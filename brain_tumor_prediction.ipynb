{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import mnist\n",
    "from torchvision.transforms import ToPILImage\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "# Create a dataloader for Pytorch training\n",
    "# download and load training dataset\n",
    "trainset = torchvision.datasets.EMNIST(root='../data', split='balanced', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# download and load testing dataset\n",
    "testset = torchvision.datasets.EMNIST(root='../data', split='balanced', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = trainset[3]\n",
    "\n",
    "# Convert PyTorch tensor to a PIL Image\n",
    "to_pil = ToPILImage()\n",
    "image_pil = to_pil(image)\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.imshow(image_pil)\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset EMNIST\n",
       "    Number of datapoints: 112800\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f440346737baf57750a9993de80ecee63827d964be75bb687e02a1dcff7748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
